---
title: "automated_lie_detection_package demo"
format:
  html:
    code-fold: true
jupyter: python3
---

# Introduction

`automated_lie_detection_package` is a Python package for classifying statements as "truthful" or "deceptive" using machine learning models. It provides a simple API for making predictions and can be integrated into various applications.

![Streamlit App Welcome Page](images/welcome_page.png)

# Installation

```bash
pip3 install -e src
```

> **Note:**  
> Depending on your environment, you may need to use `pip` instead of `pip3`, and `python` instead of `python3`.  
> For example:
> ```bash
> pip install -e src
> ```

# Model Folder Setup

Before making any predictions, you need to download a pretrained model into a local `models/` directory. 
By default, the following function downloads a DistilBERT model that has been pretrained to predict lies and truths.

```{python}
from automated_lie_detection_package import download_model_folder_from_gdrive

download_model_folder_from_gdrive()
```

**Folder structure should look like:**
```
your_project/
├── models/
│   └── [model files here]
├── data/
│   └── exp_data/
├── src/
│   └── automated_lie_detection_package/
│       └── ...
├── run.sh
└── ...
```

# Supported Model Types

The `modelprediction` and `batch_modelprediction` function expects a model folder containing files for a Hugging Face Transformers **sequence classification model** (such as DistilBERT, BERT, RoBERTa, etc.) that can be loaded with `AutoTokenizer.from_pretrained` and `AutoModelForSequenceClassification.from_pretrained`.

**Requirements:**

- All necessary files (e.g., `config.json`, `pytorch_model.bin`, `tokenizer.json`, `vocab.txt`, etc.).
- Model trained or fine-tuned for sequence (text) classification tasks.

**Note:**  
Other model types (e.g., language models for text generation, token classification, etc.) are **not supported** by `modelprediction` and `batch_modelprediction`.

# Usage

## Single Statement Prediction

For a demonstration of using `modelprediction` to classify a statement, see the example below.

```{python}
from automated_lie_detection_package import modelprediction

input_text = "I swear I am innocent"

# Directly call modelprediction with just the input text
result = modelprediction(input_text)
print(result)
```

## Batch Prediction

You can run predictions on a CSV or TXT file containing multiple autobiographical statements using the `batch_modelprediction` function.

```{python}
from automated_lie_detection_package.utility import batch_modelprediction

# For a CSV file (with a column named "statement")
batch_modelprediction(
    input_file="../data/autobiographical_statements.csv",
    output_file="../data/exp_data/batch_predictions.csv",
    column="statement"
)
```

- The function will save the results as a CSV in the `data/exp_data/` folder.
- The output CSV includes the columns: `statement`, `prediction`, and `confidence (%)`.

**Notes:**
- For CSV files, make sure the column containing your statements is named correctly (default: `"statement"`).
- File type and separator are automatically detected.
- Results are saved and can be further visualized in the Streamlit app.

# Streamlit Application Features

## Single Statement Lie Detection

- **Real-time prediction:** Enter any autobiographical statement and receive an instant prediction (truthful or deceptive) with a confidence score.
- **Explainability:** See which words contributed most to the model's prediction, highlighted in green color.
- **Prediction History:** All your predictions are saved in a session history table, which you can download as a CSV (automatically saved as `data/exp_data/prediction_history.csv`).

::: {layout-ncol=2}
![Streamlit App Single Statement Lie Detection](images/single_statement_lie_detection.png)
![Streamlit App Explainability and History CSV](images/explainability_history.png)
:::

## Batch Lie Detection

- **CSV Upload or Example File:** Upload your own CSV (with any separator) or use the default example: `data/autobiographical_statements.csv`.
- **Column Selection:** Choose which column contains the statements to analyze.
- **Batch Prediction:** Run predictions on all statements in the file. Results are saved to `data/exp_data/batch_predictions_from_upload.csv`.
- **Download Results:** Download the results as a CSV.
- **Visualizations:**
  - **Prediction Distribution:** See bar and pie charts of truthful vs. deceptive predictions.
  - **Confidence Scores:** View a histogram and boxplot of the model's confidence scores, including per-class distributions.

![Streamlit App Multiple Statement Lie Detection](images/batch_lie_detection.png)

![Streamlit App Batch Prediction Results](images/batch_prediction.png)

![Bar Chart: Prediction Distribution](images/bar_plot.png)

![Pie Chart: Prediction Distribution](images/pie_chart.png)

![Histogram: Confidence Scores](images/histogram.png)

![Box Plot: Confidence by Prediction](images/box_plot.png)

# Launching the Streamlit App

If you have the run.sh script, first make it executable in your terminal: 

```bash
chmod +x run.sh
```

To launch the app, run the following command from your project root (where `run.sh` is located):

```bash
./run.sh
```

This will start the Streamlit app, which you can access in your browser (default: http://localhost:8501).

# Starting the Streamlit App Without `run.sh`

If you do **not** have the `run.sh` script (for example, if you did not clone the repo), you can start the app manually with:

```bash
python3 -m streamlit run src/automated_lie_detection_package/app.py --server.port=8501
```

> **Note:**  
> You can use `python` instead of `python3` if that's how Python is invoked on your system.  
> You can change the number after `--server.port` to any available port, as long as that port is not already in use.

# Creating `run.sh` Yourself

If you want to create the `run.sh` script for convenience, create a new file named `run.sh` in your project root with the following content:

```bash
#!/bin/bash
python3 -m streamlit run src/automated_lie_detection_package/app.py --server.port=8501
```

Or, if your environment uses `python` instead of `python3`:

```bash
#!/bin/bash
python -m streamlit run src/automated_lie_detection_package/app.py --server.port=8501
```

Then make it executable:

```bash
chmod +x run.sh
```

# Clearing the Models Folder

If you want to remove all files and subdirectories from the `models` folder (for example, before downloading a new model), use the `clear_models_folder` function:

```{python}
from automated_lie_detection_package import clear_models_folder

# This will delete all files and subfolders in the 'models' directory
clear_models_folder()
```

# Use Cases

- Automated interview analysis
- Security screening
- Academic research on deception detection
- Personal statement analysis

# API Reference

- **download_model_folder_from_gdrive(gdrive_folder_url="https://drive.google.com/drive/folders/1BByWnxuJ8gXWDPEWjPjAnU4iVaeQp1dZ?usp=sharing", output_dir="models")**  
  Downloads the pretrained model from Google Drive into the specified directory.  
  If no URL is provided, the default public model folder will be used.

- **modelprediction(input_text)**  
  Classifies a statement as "truthful" or "deceptive" and returns a message with the predicted class and confidence score.

- **batch_modelprediction(input_file, output_file, column="statement")**  
  Runs predictions on each statement in a CSV or TXT file and saves results to a new CSV with columns: statement, prediction, confidence (%).

- **clear_models_folder(models_dir="models")**  
  Deletes all files and subdirectories in the specified models folder.

# FAQ

**Q:** What input does `modelprediction` expect?  
**A:** A single string statement.

**Q:** What does the function return?  
**A:** A message string describing the predicted class ("truthful" or "deceptive") and the confidence percentage.

# License

MIT License

# Credits

Developed by Lucca Pfründer.  
Built with Python, Hugging Face Transformers, and Streamlit.